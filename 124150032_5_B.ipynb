
[cloudera@localhost ~]$ gedit mapper1.py


[cloudera@localhost ~]$ cat mapper1.py
#!/usr/bin/env python 
  
# import sys because we need to read and write data to STDIN and STDOUT 
import sys 
  
# reading entire line from STDIN (standard input) 
for line in sys.stdin: 
    # to remove leading and trailing whitespace 
    line = line.strip() 
    # split the line into words 
    words = line.split() 
      
    # we are looping over the words array and printing the word 
    # with the count of 1 to the STDOUT 
    for word in words: 
        # write the results to STDOUT (standard output); 
        # what we output here will be the input for the 
        # Reduce step, i.e. the input for reducer.py 
        print '%s\t%s' % (word, 1) 

[cloudera@localhost ~]$ gedit reducer1.py

[cloudera@localhost ~]$ cat reducer1.py
#!/usr/bin/env python 
  
from operator import itemgetter 
import sys 
  
current_word = None
current_count = 0
word = None
  
# read the entire line from STDIN 
for line in sys.stdin: 
    # remove leading and trailing whitespace 
    line = line.strip() 
    # slpiting the data on the basis of tab we have provided in mapper.py 
    word, count = line.split('\t', 1) 
    # convert count (currently a string) to int 
    try: 
        count = int(count) 
    except ValueError: 
        # count was not a number, so silently 
        # ignore/discard this line 
        continue
  
    # this IF-switch only works because Hadoop sorts map output 
    # by key (here: word) before it is passed to the reducer 
    if current_word == word: 
        current_count += count 
    else: 
        if current_word: 
            # write result to STDOUT 
            print '%s\t%s' % (current_word, current_count) 
        current_count = count 
        current_word = word 
  
# do not forget to output the last word if needed! 
if current_word == word: 
    print '%s\t%s' % (current_word, current_count) 

[cloudera@localhost ~]$ gedit Wodcnt.txt


[cloudera@localhost ~]$ cat Wodcnt.txt
Hello how are you
how is your health
how do you do

[cloudera@localhost ~]$ 


[cloudera@localhost ~]$ ls
datasets      example.txt       internetconflic.txt  reducer1.py     Videos
derby.log     example.txt~      lib                  reducer.py      Wodcnt
Desktop       Excercise 1.txt   mapper1.py           stu1.csv        Wodcnt.txt
Documents     Excercise 1.txt~  mapper.py            stu1.csv~       wordcount
Downloads     ff                mapper.py~           students.csv    workspace
eclipse       ff.txt            Music                table.txt
employee.txt  ggg.txt           per.txt              Templates
emp.txt       god               Pictures             TempStatsStore
ex1.txt       hh                Public               txn.txt
[cloudera@localhost ~]$ cat Wodcnt.txt
Hello how are you
how is your health
how do you do
[cloudera@localhost ~]$ cat Wodcnt.txt | python mapper1.py
Hello	1
how	1
are	1
you	1
how	1
is	1
your	1
health	1
how	1
do	1
you	1
do	1
[cloudera@localhost ~]$ cat Wodcnt.txt | python mapper1.py | sort -k1,1 | python reducer1.py
are	1
do	2
health	1
Hello	1
how	3
is	1
you	2
your	1
[cloudera@localhost ~]$

[cloudera@localhost ~]$ chmod 777 mapper1.py reducer1.py

[cloudera@localhost ~]$ hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.4.0.jar -file /home/cloudera/mapper1.py /home/cloudera/reducer1.py -mapper "python mapper1.py" -reducer "python reducer1.py" -input /user/cloudera/Wodcnt.txt -output /user/cloudera/samp4 


packageJobJar: [/home/cloudera/mapper1.py, /home/cloudera/reducer1.py, /tmp/hadoop-cloudera/hadoop-unjar2995590802291667993/] [] /tmp/streamjob7576603973573790331.jar tmpDir=null
23/08/02 05:06:40 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
23/08/02 05:06:40 INFO mapred.FileInputFormat: Total input paths to process : 1
23/08/02 05:06:40 INFO streaming.StreamJob: getLocalDirs(): [/tmp/hadoop-cloudera/mapred/local]
23/08/02 05:06:40 INFO streaming.StreamJob: Running job: job_202308020457_0003
23/08/02 05:06:40 INFO streaming.StreamJob: To kill this job, run:
23/08/02 05:06:40 INFO streaming.StreamJob: UNDEF/bin/hadoop job  -Dmapred.job.tracker=localhost.localdomain:8021 -kill job_202308020457_0003
23/08/02 05:06:40 INFO streaming.StreamJob: Tracking URL: http://0.0.0.0:50030/jobdetails.jsp?jobid=job_202308020457_0003
23/08/02 05:06:41 INFO streaming.StreamJob:  map 0%  reduce 0%
23/08/02 05:06:48 INFO streaming.StreamJob:  map 100%  reduce 0%
23/08/02 05:06:53 INFO streaming.StreamJob:  map 100%  reduce 100%
23/08/02 05:06:55 INFO streaming.StreamJob: Job complete: job_202308020457_0003
23/08/02 05:06:55 INFO streaming.StreamJob: Output: /user/cloudera/samp4





[cloudera@localhost ~]$ hadoop fs -ls samp4/
Found 3 items
-rw-r--r--   3 cloudera cloudera          0 2023-08-02 05:06 samp4/_SUCCESS
drwxr-xr-x   - cloudera cloudera          0 2023-08-02 05:06 samp4/_logs
-rw-r--r--   3 cloudera cloudera         52 2023-08-02 05:06 samp4/part-00000
[cloudera@localhost ~]$ hadoop fs -cat /user/cloudera/samp4/part-00000
Hello	1
are	1
do	2
health	1
how	3
is	1
you	2
your	1


 

