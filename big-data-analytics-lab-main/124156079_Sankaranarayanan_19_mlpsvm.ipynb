{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZIAdPXcXKcS",
        "outputId": "4e1b9ae4-f621-4410-ed7a-02116495113c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/admin123/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
            "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LinearSVC, MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"MLP_SVM_Iris\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "data = spark.read.csv(\"IRIS.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Prepare the features\n",
        "feature_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Convert string labels to numerical values\n",
        "label_indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
        "data = label_indexer.fit(data).transform(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8PAwArOXKcX",
        "outputId": "8d0a6846-e727-424b-f7b7-c3c9bfece4a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[sepal_length: double, sepal_width: double, petal_length: double, petal_width: double, species: string, features: vector, label: double]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQdFOdVvXKcY"
      },
      "outputs": [],
      "source": [
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"label\", layers=[4, 10, 5, 3])  # Adjust layers as needed\n",
        "mlp_model = mlp.fit(train_data)\n",
        "\n",
        "# Evaluate the models\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3wavCngXKcY",
        "outputId": "b686233c-8704-46ba-ab96-a4e3665fc42d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Accuracy: 0.9565217391304348\n"
          ]
        }
      ],
      "source": [
        "mlp_predictions = mlp_model.transform(test_data)\n",
        "mlp_accuracy = evaluator.evaluate(mlp_predictions)\n",
        "print(\"MLP Accuracy:\", mlp_accuracy)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLdj0LzAXKcZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "num_samples = 1000  # Number of samples\n",
        "num_features = 2    # Number of features\n",
        "\n",
        "# Create feature matrix\n",
        "X = np.random.rand(num_samples, num_features)\n",
        "\n",
        "# Create labels (binary classification problem)\n",
        "y = np.random.randint(2, size=num_samples)\n",
        "\n",
        "# Save the synthetic dataset as a CSV file\n",
        "data = np.column_stack((X, y))\n",
        "df = pd.DataFrame(data, columns=[f'feature{i}' for i in range(num_features)] + ['label'])\n",
        "df.to_csv('synthetic_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njdJazo1XKca",
        "outputId": "615b3c5f-4318-4f8e-de0d-d5901d22c0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5703125\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"LinearSVCExample\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "data = spark.read.csv(\"synthetic_dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Prepare the features\n",
        "feature_columns = [\"feature0\", \"feature1\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Implement LinearSVC model\n",
        "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
        "svm_model = svm.fit(train_data)\n",
        "\n",
        "# Make predictions\n",
        "svm_predictions = svm_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model using accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(svm_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhB9wUIbXKca"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}